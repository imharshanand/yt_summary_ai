{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bd5f9e-68f7-4e1b-8236-4e7765ae6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-api-python-client youtube-transcript-api openai\n",
    "# pip install sentencepiece\n",
    "# openai --version # 1.34.0\n",
    "\n",
    "# pip install transformers\n",
    "# pip install torch\n",
    "# pip install google-api-python-client\n",
    "# pip install youtube-transcript-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d803f22-9b49-4b31-b99c-53601117553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/envs/llm_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Replace with your API keys and channel ID\n",
    "API_KEY = 'AIzaSyDeGQSEB_xxxxxxxxxxxxxxxxx'\n",
    "CHANNEL_ID = 'UCXuqSxxxxxxxxxxxxxxxxx'\n",
    "OPENAI_API_KEY = 'sk-proj-YQ1mbN9Hxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' # not needed as local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7aafdfd-8a10-4613-a2d6-c0b7a355f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save and load models\n",
    "model_dir = \"./model\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Create the model directory if it doesn't exist\n",
    "\n",
    "# Initialize the T5 model and tokenizer\n",
    "model_name = 't5-small'  # you can use 't5-base' for better performance\n",
    "\n",
    "# Save the model and tokenizer\n",
    "def save_model(model_name, model_dir):\n",
    "    \"\"\"\n",
    "    Save the T5 model and tokenizer to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model to download and save.\n",
    "        model_dir (str): The directory where the model and tokenizer will be saved.\n",
    "    \"\"\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dc5c66-19e3-4285-84dd-de36a6622d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "def load_model(model_dir):\n",
    "    \"\"\"\n",
    "    Load the T5 model and tokenizer from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir (str): The directory from where the model and tokenizer will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        model: The loaded T5 model.\n",
    "        tokenizer: The loaded T5 tokenizer.\n",
    "    \"\"\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_dir).to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26fd62d-9a0b-4f2c-8698-d2ebbb19927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Check if the model already exists in the directory; if not, download and save it\n",
    "if not os.path.exists(os.path.join(model_dir, 'config.json')):\n",
    "    save_model(model_name, model_dir)\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the model and tokenizer\n",
    "model, tokenizer = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cbb4ef-cb28-4564-bc17-4010ca01f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61dc3f18-5b57-41e5-a345-682eb04265cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_video(api_key, channel_id):\n",
    "    \"\"\"\n",
    "    Retrieve the latest video from a specified YouTube channel.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): YouTube API key.\n",
    "        channel_id (str): YouTube channel ID.\n",
    "\n",
    "    Returns:\n",
    "        video_id (str): The ID of the latest video.\n",
    "        video_title (str): The title of the latest video.\n",
    "    \"\"\"\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    # Create a request to get the latest video from the channel\n",
    "    request = youtube.search().list(\n",
    "        part='snippet',\n",
    "        channelId=channel_id,\n",
    "        order='date',\n",
    "        maxResults=1\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    # Check if there are any videos in the response\n",
    "    if 'items' in response:\n",
    "        latest_video = response['items'][0]\n",
    "        video_id = latest_video['id']['videoId']\n",
    "        video_title = latest_video['snippet']['title']\n",
    "        return video_id, video_title\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e0a6ee-13f7-45a8-a8d7-714eb52cfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "    \"\"\"\n",
    "    Retrieve the transcript of a specified YouTube video.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The ID of the YouTube video.\n",
    "\n",
    "    Returns:\n",
    "        transcript_text (str): The full transcript text of the video.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the transcript of the video\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        # Join all the transcript segments into a single string\n",
    "        transcript_text = ' '.join([item['text'] for item in transcript])\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving transcript: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a377d55-2798-4a42-9687-15edec54d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    Summarize the provided text using the T5 model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be summarized.\n",
    "\n",
    "    Returns:\n",
    "        summary (str): The summarized text.\n",
    "    \"\"\"\n",
    "    # Encode the input text and move it to the appropriate device\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    # Generate the summary using the T5 model\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    # Decode the generated summary and return it\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48101fd8-6d80-4db6-877d-f81948f221f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest video ID: uxsTpMXzEU0, Title: Hey Siri, Iâ€™m Giving You A Second Chance\n",
      "Transcript retrieved successfully.\n",
      "Summary:\n",
      "new AI enhanced functions are now built into all of apple's operating systems that allow you to quickly generate smart replies proofread or rewrite messages and summarize content which is probably the most useful tool for me though is reduce interruptions. how is all of this working well Apple claims that their machine learning algorithms primarily run on device as they always have but because of the increasing complexity of these tasks.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Get the latest video from the specified channel\n",
    "    video_id, video_title = get_latest_video(API_KEY, CHANNEL_ID)\n",
    "    if video_id:\n",
    "        print(f\"Latest video ID: {video_id}, Title: {video_title}\")\n",
    "        # Get the transcript of the latest video\n",
    "        transcript = get_transcript(video_id)\n",
    "        if transcript:\n",
    "            print(\"Transcript retrieved successfully.\")\n",
    "            # Summarize the transcript\n",
    "            summary = summarize_text(transcript)\n",
    "            print(\"Summary:\")\n",
    "            print(summary)\n",
    "        else:\n",
    "            print(\"Failed to retrieve transcript.\")\n",
    "    else:\n",
    "        print(\"No videos found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
